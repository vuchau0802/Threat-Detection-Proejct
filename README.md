# Threat Detection using Machine Learning
Detecting and classifying harmful online content using NLP and supervised machine learning.
---

## Overview
This project aims to **detect cyberbullying** and offensive language on social media platforms using Natural Language Processing (NLP) and machine learning models.  
It demonstrates an end-to-end ML pipeline â€” from text preprocessing and feature extraction to model training and web deployment using Flask.

---

## Features
- Detects and classifies online text as safe or harmful.  
- Preprocessing includes tokenization, stemming, and TF-IDF vectorization.  
- Multiple ML models trained and compared:
  - Logistic Regression  
  - XGBoost  
  - Naive Bayes  
  - Random Forest  
  - Decision Tree  
- Achieved **92% accuracy (F1 = 0.89)** on 72K+ labeled posts.  
- Real-time predictions through a simple Flask web app.  
- Generates a **bullying severity score** for interpretability.
---
